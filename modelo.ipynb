{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxic Comment Classification Challenge\n",
    "## Identify and classify toxic online comments\n",
    "\n",
    "El problema conciste en crear un modelo el cual clasifique los textos en 6 categorias:\n",
    "1. comment_text\n",
    "2. toxic\n",
    "3. severe_toxic\n",
    "4. obscene\n",
    "5. threat\n",
    "6. insult\n",
    "7. identity_hate\n",
    "\n",
    "Para ello se dividira el proceso en las siguientes etapas:\n",
    "1. [Preprocesamiento](#pre)\n",
    "2. [Analisis estadístico](#eda)\n",
    "3. [Modelado y Evaluación](#mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paqueterías\n",
    "Aqui se incluyen las paqueterias necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from gensim.models import Phrases\n",
    "from funcs import entidades, quitarpuntuacion, bigramas\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pre'></a>\n",
    "## Preprocesamiento\n",
    "\n",
    "El preprocesamiento conciste en limpriar los textos para poder despues . Primero cargamos los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv',index_col=0)\n",
    "test = pd.read_csv('data/test.csv')\n",
    "subm = pd.read_csv('data/sample_submission.csv')\n",
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "train['limpio'] = 1-train[label_cols].max(axis=1)\n",
    "train['comment_text'].fillna(\"unknown\", inplace=True)\n",
    "test['comment_text'].fillna(\"unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que contiene el archivo de train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22256635</th>\n",
       "      <td>Nonsense?  kiss off, geek. what I said is true...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27450690</th>\n",
       "      <td>\"\\n\\n Please do not vandalize pages, as you di...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54037174</th>\n",
       "      <td>\"\\n\\n \"\"Points of interest\"\" \\n\\nI removed the...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77493077</th>\n",
       "      <td>Asking some his nationality is a Racial offenc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79357270</th>\n",
       "      <td>The reader here is not going by my say so for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comment_text  toxic  \\\n",
       "id                                                                   \n",
       "22256635  Nonsense?  kiss off, geek. what I said is true...      1   \n",
       "27450690  \"\\n\\n Please do not vandalize pages, as you di...      0   \n",
       "54037174  \"\\n\\n \"\"Points of interest\"\" \\n\\nI removed the...      0   \n",
       "77493077  Asking some his nationality is a Racial offenc...      0   \n",
       "79357270  The reader here is not going by my say so for ...      0   \n",
       "\n",
       "          severe_toxic  obscene  threat  insult  identity_hate  \n",
       "id                                                              \n",
       "22256635             0        0       0       0              0  \n",
       "27450690             0        0       0       0              0  \n",
       "54037174             0        0       0       0              0  \n",
       "77493077             0        0       0       0              0  \n",
       "79357270             0        0       0       0              0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observemos el texto del segundo renglón."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\n\\n Please do not vandalize pages, as you did with this edit to W. S. Merwin. If you continue to do so, you will be blocked from editing.    \"'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[1].comment_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que haremos en el pre-procesamiento va a ser:\n",
    "- Quitar saltos de linea (\\n)\n",
    "- Quitar puntuación y simbolos (.:;,!\"#$%&/()=?)\n",
    "- Separar las palabras y crear n-gramas, por ejemplo en vez de separar en tres palabras \"W.\", \"S.\" y \"Merwin\", que sea una sola palabra, aun que en realidad se podrian borrar estas palabras, ya que no son importantes para la clasificación.\n",
    "- Tokeniza, que es separar las palabras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "train = quitarpuntuacion(train)\n",
    "docs = train.comment_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La parte de tokenizar y crear los bigramas se hacen con funciones definidas en el archivo funcs.py que esta en la misma carpeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "docs = entidades(docs,nlp)\n",
    "docs = bigramas(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que este ultimo procesa lleva una tiempo considerable se guarda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump( docs, open( \"save.p\", \"wb\" ) )\n",
    "\n",
    "docs = pickle.load( open( \"save.p\", \"rb\" ) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eda'></a>\n",
    "## Analisis estadistico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='mod'></a>\n",
    "## Modelo y evaluación\n",
    "Debido a que los datos a predecir son categorias y no son excluyentes, es decir un documento puede pertenecer a dos o más categorias se debe hacer un modelo para cada categoria. Para un primer ejercicio se usaran los siguientes modelos:\n",
    "- Naive Bayes multinomial\n",
    "- Regresión Logistica\n",
    "- Stochastic Gradient Descent\n",
    "\n",
    "Antes de configurar los modelos los datos se tienen que veectorizar, i.e. acomodar en una matriz numérica, por lo se se usa Tf-idf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['texto_limpio'] = docs\n",
    "#train['texto_limpio'] = train['texto_limpio'].apply(lambda x: ' '.join(x))\n",
    "del train['comment_text']\n",
    "del train['limpio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se divide los datos en datos de entrenamiento y datos de prueba, para despues vectorizarlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%Dividir\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train.iloc[:,6], train.iloc[:,0:6],test_size=0.2)\n",
    "\n",
    "#%%\n",
    "vectorizer = TfidfVectorizer(stop_words = 'english',\\\n",
    "                             vocabulary=None,\\\n",
    "                             analyzer='word',\\\n",
    "                             lowercase=True,\\\n",
    "                             ngram_range=(1, 1),\\\n",
    "                             max_df=1.0,\\\n",
    "                             min_df=1)\n",
    "\n",
    "tfidf_train = vectorizer.fit_transform(X_train)\n",
    "tfidf_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reglog = LogisticRegression()\n",
    "presicion_reglog = dict()\n",
    "\n",
    "for label in label_cols:\n",
    "    y = y_train[label]\n",
    "    reglog.fit(tfidf_train, y)\n",
    "    y_hat = reglog.predict(tfidf_test)\n",
    "    presicion_reglog[label] = accuracy_score(y_test[label], y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "naive_bayes = MultinomialNB()\n",
    "presicion_naive_bayes = dict()\n",
    "\n",
    "for label in label_cols:\n",
    "    y = y_train[label]\n",
    "    naive_bayes.fit(tfidf_train, y)\n",
    "    y_hat = naive_bayes.predict(tfidf_test)\n",
    "    presicion_naive_bayes[label] = accuracy_score(y_test[label], y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent\n",
    "> Nota: Independiente al resultado de este modelo, para la competencia de kaggle no funciona ya que los datos que tienes que regresar es una probabilidad, y SGD regresa si pertenece o no a la categoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pepe/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "SGDC = SGDClassifier()\n",
    "presicion_SGDC = dict()\n",
    "\n",
    "for label in label_cols:\n",
    "    y = y_train[label]\n",
    "    SGDC.fit(tfidf_train, y)\n",
    "    y_hat = SGDC.predict(tfidf_test)\n",
    "    presicion_SGDC[label] = accuracy_score(y_test[label], y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.979816178391\n",
      "0.966624889028\n",
      "0.976844743851\n"
     ]
    }
   ],
   "source": [
    "print(sum(list(presicion_reglog.values()))/6)\n",
    "print(sum(list(presicion_naive_bayes.values()))/6)\n",
    "print(sum(list(presicion_SGDC.values()))/6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo que elgimos la regresión logistica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submission\n",
    "Por ultimo creamos el archivo para subirlo a la competencia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_train_c =vectorizer.fit_transform(train['texto_limpio'])\n",
    "tfidf_sub = vectorizer.transform(test['comment_text'])\n",
    "\n",
    "for label in label_cols:\n",
    "    y = train[label]\n",
    "    reglog.fit(tfidf_train_c, y)\n",
    "    test[label] = reglog.predict_proba(tfidf_sub)[:,1]\n",
    "#%%\n",
    "\n",
    "#%%\n",
    "subm = test\n",
    "del subm[\"comment_text\"]\n",
    "#%%\n",
    "subm.to_csv('subs/submission5.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué sigue?\n",
    "Para mejorar el modelo, las ideas que se podrian hacer son:\n",
    "- Mejorar el preprocesamiento: aumentar los bi-gramas a n-gramas, filtrar palabras comunes aunque no sean stop words\n",
    "- Mejorar la vectorización: Reducir el tamaño, eliminando palabras\n",
    "- Probar más modelos: Usar redes nuronales, otros clasificadores(e.g. NB-SVM).\n",
    "- Ver la calidad del modelo logistico: Checar curva ROC, Recall, Presicion, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
